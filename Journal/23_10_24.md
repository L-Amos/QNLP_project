# Day 5: 23rd October 2024
## Entry 1: 11:49
Quick one today; I wasn't planning on doing any work today, but I had an idea I'd quite like to try out.

The current problem I'm working on is finding a good way to evaluate my fidelity test (i.e to test if it actually rates sentence similarity in a useful way). The current idea I have is to use a BERT model to run through each sentence in the test array and for each sentence rank all the sentences in the train array by similarity. I can then perform the same thing with my quantum swap test circuit, and then compare the ranked arrays. This is essentially creating a *classical* recommender system to evaluate the fidelity test before moving on to creating a *quantum* recommender system. Since I have so many investigations planned for this fidelity test circuit, finding a good way to evaluate its performance is essential.

The manner in which I compare the ranked arrays is up for debate, but [NDCG](https://www.geeksforgeeks.org/normalized-discounted-cumulative-gain-multilabel-ranking-metrics-ml/) appears to be a pretty ubiquitous metric for such a comparison, so I'll probably use that. My primary goal for now is to get a BERT model downloaded and spitting out similarities.