# Day 2: 9th October 2024
## Entry 1: 09:49
Today I want to play around with lambeq. Specifically, I want to train a model using the training data from Lorentz. et al [^1][^2] and then poke and prod that model to see what happens. Specifically, I want to test the model with a sentence very similar to one of its training sentences, then implement the state fidelity circuit I got working last time to see just how close the two states are. If they're miles apart, this whole QKNN thing won't work, and I'll have to alter the training phase somehow.

I'll be using binary classification for now, as I need a simple approach. I tried to get Lorentz et al's code[^3] working, but as it was written 3-4 years ago packages and libraries have been updated - I think it would be more beneficial to start from scratch with the latest versions and methods of the various packages.


[^1]: https://arxiv.org/pdf/2102.12846
[^2]: https://github.com/CQCL/qnlp_lorenz_etal_2021_resources/tree/main/datasets/ 
[^3]: https://github.com/CQCL/qnlp_lorenz_etal_2021_resources