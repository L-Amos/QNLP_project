# Day 1: 2nd October 2024
## Entry 1: 09:57
Yesterday Professor Sadrzadeh and I agreed on a title for this master's project: **Combining Statistical and Structured Quantum Methods in NLP**. I am excited to make a start.

Today I will be running some initial tests with lambeq. As I have never used this package before (and until last week had never heard of it) I need to play around with it to understand how it works, and how I can use it in my project.

I plan to parse some rudimentary sentences to understand how lambeq translates them into quantum circuits. I plan on parsing three sentences:

- Bob hates Alice
- Alice does not hate Bob
- Alice likes Chris

These sentences are quite good starting points, as they are all related to each other in some way. It will give me an idea of how related sentences are translated into quantum circuits - if the circuits are totally different from one another, the machine learning using the $k$ nearest neighbours algorithm will be difficult.

I plan on parsing these sentences in different orders with each test, to see if the order changes the circuits produced. I believe this will be the case, as from my reading the circuits are initially created using *ansätze*, and then subsequent circuits are refined using the initial circuit produced (provided the succeeding sentences relate to the initial sentence parsed).

## Entry 2: 11:33
I'm an idiot.

I've only just realised that the *entire point* of starting with an ansätz is to allow the parameters of the circuit to be chosen *based on what you want the measurement outcome to be*. So for example, if I wanted a sentence to be sorted under 'sport', I could choose the qubit state $\frac{1}{\sqrt{2}}(|0\rangle + |1\rangle)$ to represent this category, and then pick my parameters to maximise the likelihood of measuring this state.

## Entry 3: 13:03
Ok, after a fair bit of research I might have an idea. It doesn't make sense to implement QKNN in the training phase of the lambeq pipeline, since KNN doesn't actually train any models. Therefore, I am merely 'bolting on' KNN support after the initial training data has been used.

I still think this is worthwhile; in the current approach, SPSA is used both for training and test data, however I think it would be better to use QKNN for this, as it allows for a directly *quantum* comparison between the states, without having to measure the states beforehand. This should improve accuracy, and would allow for multiclass classification through the use of mixed states.