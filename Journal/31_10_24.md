# Day 8: 31st October 2024
## Entry 1: 16:19
Yesterday I had a meeting with Professor Sadrzadeh. One of the outcomes of the meeting was that I should train my model in a different way; currently the model is trained for binary classification tasks, whereas my task is, at the most fundamental level, determining the similarity between two sentences correctly. As such, I need to train my model to be able to do that properly. And I've had an idea which she agrees with.

My idea is to train the model using **pairs** of sentences, not the sentences themselves. The label for each pair will be the SBERT cosine similarity between the two sentences. During training, each sentence in the pair will be converted to a PQC, composed together, and the fidelity will be measured ([as I have done previously](/src/state_fidelity.py)). Thus the loss function will be the MSE between the SBERT similarity and the measured fidelity. I am extremely excited about implementing this.

Furthermore, Professor Sadrzadeh has shared with me data from a paper one of her former students is currently working on. In this paper he has generated short synopses for 146 BBC television programmes, and has collected user data for each of these programs. His aim is to train a model to recommend the programmes based on their synopses and user data (i.e who watched what). This user data gives a "similarity" between the two programmes. She thinks I might be able to incorporate my quantum approach into this research. While at the time I was a little bemused, I now see a pathway.

My current aim is to be able to train a model to find the similarity between two sentences given training data with SBERT similarities between pairs of sentences. If I instead replace the sentences with programme synopses and the SBERT similarities with the similarity from the user data, my model should be able to find the "similarity" between a pair of programmes, which would represent the likelihood that if someone watched one of them, they will want to watch the other.

There is a subtle difference, though; in my work, I care about *semantic similarity*, whereas for the BBC programmes you would more care about the *context and phrases* of the sentence. As a result, while DisCoCat is a good model for my work, a bag-of-words or word-sequence model may be better suited to the BBC programmes. These simpler models would also reduce the training time .

This is all very exciting, and is driving me forwards with extreme purpose. My current aim is to train a model for similarity measurements, as described above. If this is successful on my limited-vocabulary dataset, I can look at extending it to the case of BBC programmes.

The reason I am so late in starting today is because I was doing some research on ML techniques to try and bring my knowledge up to scratch; this current challenge is much more of a machine-learning challenge than I was expecting to encounter! I suppose you never stop being naive.
