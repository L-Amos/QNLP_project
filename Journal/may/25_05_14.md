# Day 17: 14th May 2025
## Entry 1: 09:45
It's been a while. I have worked on this project since, but honestly not very much. Job interviews, Easter and revision have taken up all of my time and willpower, and I find myself a little daunted at the work I need to catch up on. With only one exam to go in two weeks, I have a lull in my revision which I can use to get a grip and get back on track.

Two major developments since I last worked on this project. Firstly, I completed my literature review, which really brought back into focus the overall point of this project. I had lost sight of the fact that I was trying to combine statistical **and structural** QNLP. This structural element comes from DisCoCat, and so it is pointless to spend time on other language models like bag-of-words or word-sequence as they encompass much less language structure. The point of this is to see whether the statistical approach of KNN (QKNN in my case) can be effectively married with the structural approach of DisCoCat. With this clear focus, I am no longer comparing against other language models, because I am not aiming to compete with syntax-free models.

Secondly, I had a meeting with my supervisor, Professor Sadrzadeh. Work which I did not log included incorporating a classical KNN algorithm to a trained fidelity model and performing simple binary sentence classification, the results of which I compared to other language models such as bag-of-words and word-sequence. I was greatly excited by results,and frankly I was expecting them to be met with praise. She emailed back and said she didn't understand the point of what I had done. I received this response in the middle of an incredibly busy and stressful period, and so in that moment my interest in this project snapped. I now of course realise she was completely right - as explained above, there is no point in comparing to these other language models because I am not seeing if my model is better, I am seeing if my model works with QKNN *at all*. We know unstructured/statistical approaches work well - I want to see if a structured/statistical approach is possible. 

Our meeting uncovered several things I need to do. Several regrettably *fundamental* things. Essentially, I need a better way of expressing convergence results. My supervisor suggested plotting the correlation between the train pairs and their fidelities as training progresses, and when it came to accuracy, to decide on an appropriate 'margin of error' for a calculated fidelity to be considered 'correct', and using this to determine the overall training accuracy. These will give more insights into how well my model trains.

Unfortunately, it seems I am essentially starting from scratch here. Using these new methods of expressing training efficacy, I want to reinvestigate the best loss metrics and ansatze to use. I also want to change the fundamental circuit - rather than composing two sentence circuits together in parallel, I want to compose them in series. This will reduce the dimensionality of the system and therefore should be faster to simulate. It pains me that I'm starting from scratch, but on the plus side since I am now (more or less) able to spend all my time on this project, and since I have only spent 16 days on it so far, it should only take a few weeks to get back to where I was. I don't mind long hours.

My tasks are therefore as follows:
1. Read through my literature review to re-familiarise myself with the project.
2. Create a new 'serial circuit' branch and try to compose sentence circuits in serial, rather than in parallel.
3. Investigate how to calculate the correlation between the fidelities outputted by my model and the train labels (which are SBERT similarities).
4. Plot this correlation with training epoch to gain further insight into training efficacy.
5. Do the same with a chosen 'margin of error' and plot training accuracy with epoch.
6. Investigate whether I can use more training pairs without the problem becoming intractable - more training pairs = more chance the model converges.
7. Investigate which sentence ansatz leads to the best training.
8. Investigate which loss metric leads to the best training.

Better get to work!